---
title: "Credit Card Default"
author: "Dareck Giuliani, Jacob Summerhays, and Sam Wilson"
date: "12/2/2020"
output:
  html_document:
    toc: yes
---

# Define

Primarily, we intend to create a model that predicts default rate. We will also answer the following questions:

1. How does the probability of default payment vary by categories of different demographic variables?
2. Which variables are the strongest predictors of default payment?

# Collect

The following libraries will be used:

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse) #for manipulating and visualizing data
library(MASS) #has function stepAIC(), which allows for easy stepwise regression
library(psych) #dummy code function
library(fastDummies) #dummy code function
library(caret) #for computing cross-validation methods
library(pROC) #to create ROC curves
library(ROCR) #an alternate ROC curve package
library(class) #for the knn() function
library(randomForest) #for the random forest classifier
library(gbm) #for GBM function
library(gdata) #to rename columns 
library(cvTools) #to perform corss validation
select <- dplyr::select

options(scipen=999) #effectively eliminates scientific notation

```

## The Raw Data

This dataset contains information about default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.

### Variables

#### Independent Variables

* ID: ID of each client
* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit
* SEX: Gender (1=male, 2=female)
* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
* MARRIAGE: Marital status (1=married, 2=single, 3=others)
* AGE: Age in years
* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, â€¦ 8=payment delay for eight months, 9=payment delay for nine months and above)
* PAY_2: Repayment status in August, 2005 (scale same as above)
* PAY_3: Repayment status in July, 2005 (scale same as above)
* PAY_4: Repayment status in June, 2005 (scale same as above)
* PAY_5: Repayment status in May, 2005 (scale same as above)
* PAY_6: Repayment status in April, 2005 (scale same as above)
* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)
* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)
* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)
* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)
* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)
* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)
* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)
* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)
* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)
* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)
* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)
* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)

#### Dependent Variables

* default.payment.next.month: Default payment (1=yes, 0=no)


```{r read in data, echo=TRUE}

#read in data
creditDf <- read.csv('UCI_Credit_Card.csv')
#https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset

#standardize column names
colnames(creditDf) <- tolower(make.names(colnames(creditDf)))

head(creditDf)

```

# Organize

## Cleaning the Data

```{r understanding the data, echo=TRUE}

#dimensions
dim(creditDf)

#missing values
sum(is.na(creditDf))

#summary
summary(creditDf)

# What is the ratio of defaults?
sum(creditDf$default.payment.next.month)/length(creditDf$default.payment.next.month)

```

### Correcting the Data Types

1. Alter Sex to be a 0-1 variable and ensure it is categorical. 
2. Education has one level for other and two levels for unknown. Each of these will be grouped together. 
3. Education had a few entries of 0, this will be grouped with other and unknown. 
3. Education is then made into a categorical variable. 
4. Marriage is made into a categorical variable. 
5. Marriage has a few entries of 0. These value has no meaning, it will be grouped with other. 
6. The dependent variable, credit default, it made into a categorical variable. 
7. Each of the pay variables is made into a categorical variable. 
8. Each of the pay variables has an entry of -2. This is an erroneous entry and instead the absolute value is used. 

### Feature Engineering

1. An average is taken of all the bill amount variables. 
2. An average is taken of all the pay amount variables. 
3. A ratio of bill amount to pay amount is created. 
4. A variable for limit use is also created by dividing average bill over limit. 
5. All of the categorical variables are made into dummy variables. 

```{r correct date types, echo=TRUE}

creditDf <- creditDf %>%
  mutate(
    
    # Data Cleaning
    
    # Make sex a binary variable (1=female, 0 = male) and make it categorical.
    sex = as.factor(if_else(creditDf$sex == 2, true = 1, false = 0)),
    
    # Education contains these three repetitive levels: 4=others, 5=unknown, 6=unknown. This next line is to consolidate the the three levels into one level. Additionally, some entries have education labeled as 0. 0 is not a known level according to the given key. As such, 0 will be grouped with others and unknown. Education is made into a categorical variable as well. 
    education = as.factor(ifelse(creditDf$education > 4 | creditDf$education == 0, 4, creditDf$education)),
    
    # Some entries of marriage are labeled as 0. However, the key given to us, does not provide meaning for 0. Thus, values for marriage of 0 will be grouped into the other bin. 
    #make marriage a categorical variable
    marriage = as.factor(ifelse(creditDf$marriage == 0, 3, creditDf$marriage)),
    
    # The dependent variable is made into a categorical variable (1 = yes, 0 = no). 
    default.payment.next.month = as.factor(creditDf$default.payment.next.month),
    
    # The pay variables have values of -2. However, -2 is never provided in the key. I am imputing the absolute value instead. Each pay variable is made into a categorical variable. 
    pay_0 = factor(ifelse(creditDf$pay_0 == -2, 2, creditDf$pay_0)),
    pay_2 = factor(ifelse(creditDf$pay_2 == -2, 2, creditDf$pay_2)),
    pay_3 = factor(ifelse(creditDf$pay_3 == -2, 2, creditDf$pay_3)),
    pay_4 = factor(ifelse(creditDf$pay_4 == -2, 2, creditDf$pay_4)),
    pay_5 = factor(ifelse(creditDf$pay_5 == -2, 2, creditDf$pay_5)),
    pay_6 = factor(ifelse(creditDf$pay_6 == -2, 2, creditDf$pay_6)),
    

    
    # Feature Engineering
    
    bill_avg = round((creditDf$bill_amt1 + creditDf$bill_amt2 + creditDf$bill_amt3 + creditDf$bill_amt4 + creditDf$bill_amt5 + creditDf$bill_amt6)/6, 2),
    
    pay_avg = round((creditDf$pay_amt1 + creditDf$pay_amt2 +creditDf$pay_amt3 + creditDf$pay_amt4 + creditDf$pay_amt5 + creditDf$pay_amt6 ) /6,2),
    
    #Credit scores often judge a person on their credit usage. The closer to the limit a person is, the more of a negative impact on credit score. This metric will divide the average bill amount by the limit balance to get a sense of the average credit usage.
    avg_credit_usage = round(bill_avg/limit_bal, 2),

    
  ) %>%
  
  # ID is dropped as it will have no predictive power. 
  select(-c(id))

# This will show the data type of each variable within the data frame. 
sapply(creditDf, class)

# Additionally, I'd like to see some basic statistics of the cleaned data.
summary(creditDf)

```


```{r Useful Subsets, echo=TRUE}

# Useful Subsets

# This creates a data frame of all categorical variables.
categorical <- select(creditDf, c(sex, education, marriage, default.payment.next.month, pay_0, pay_2, pay_3, pay_4, pay_5, pay_6))

# This creates a data drame of all continuous variables.
continuous <- select(creditDf, -c(sex, education, marriage, default.payment.next.month, pay_0, pay_2, pay_3, pay_4, pay_5, pay_6))

# This dummy codes all categorical variables. 
dummy <- select(creditDf, c(education, marriage, pay_0, pay_2, pay_3, pay_4, pay_5, pay_6))

creditDf_Dummy <- dummy_cols(creditDf, select_columns = colnames(dummy))

# The following lines of codes create a data frame with scaled values for the continuous variables. 
creditDf_Scaled <- creditDf %>%
  select(-c(sex, education, marriage, default.payment.next.month, pay_0, pay_2, pay_3, pay_4, pay_5, pay_6)) %>%
  scale() %>%
  data.frame()

creditDf_Scaled <- cbind(creditDf_Scaled, categorical)

creditDf_Scaled <- rename.vars(creditDf_Scaled, from = dput(names(continuous)), to = paste0('scaled.', dput(names(continuous))))

# The following creates testing and training data sets.

# Creates a sample of 80% of the data
sample_size <- floor(.8 * nrow(creditDf))

#
set.seed(123)
train_index <- sample(seq_len(nrow(creditDf)), size = sample_size)

# This is a training and testing set with no scaled data. 
train <- creditDf[train_index, ]
test <- creditDf[-train_index, ]

# This is a training and testing set with scaled data. 
train_scaled <- creditDf_Scaled[train_index, ]
test_scaled <- creditDf_Scaled[-train_index, ]


```

## Descriptive Statistics

# Visualize

To begin, the below is a visualization of the ratio of default to no defaults.

```{r default rate, echo=TRUE}

creditDf %>%
  ggplot(aes(x = default.payment.next.month)) +
  geom_bar() +
  ylab('Count') +
  xlab('Default (1 = yes)') +
  ggtitle('The Number of Defaults in the Dataset') +
  theme_minimal()

```

Now, we examine the relationship between demographic variables and defaulting. 

```{r visualize demo, echo=TRUE, message=FALSE, warning=FALSE}

# 1 = Female, 0 = Male
sex.label <- c('Female', 'Male')
names(sex.label) <- c('1', '0')
# 1 = Married, 2 = Single, 3 = Other
marriage.label <- c('Married', 'Single', 'Other')
names(marriage.label) <- c('1', '2', '3')

creditDf %>%
  group_by(sex, marriage, education, default.payment.next.month) %>%
  tally() %>%
  mutate(
    proportion = n/sum(n)
  )  %>%
  ggplot(aes(x = education, y = proportion, fill = default.payment.next.month)) +
  geom_col() +
  facet_wrap(~sex + marriage, 
             #labeller(sex = sex.label,
              #        marriage = marriage.label)
             ) +
  xlab('Education') +
  ylab('Proportion of Defaults') +
  labs(fill = 'Default 1 = yes | 0 = no') +
  ggtitle('The Proportion of Default by Education, Sex, and Marriage') +
  theme_minimal() +
  theme(
    legend.position = 'bottom',
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_x_discrete(labels  = c('1' = 'Graduate School', '2' = 'Some University', '3' = 'High School', '4' = 'Other/Unknown'), 
                   limits = seq(1, 4)
                   )

creditDf %>%
  filter(age < 75) %>%
  group_by(age, sex, default.payment.next.month) %>%
  tally() %>%
  mutate(
    proportion = n/sum(n)
  ) %>%
  ggplot(aes(x = age, y = proportion, fill = default.payment.next.month)) +
  geom_col() +
  facet_wrap(~ sex#, 
             #labeller(sex = sex.label)
             ) +
  xlab('Age') +
  ylab('Proportion') +
  ggtitle('The Proportion of Default by Age and Sex') +
  labs(fill = 'Default 1 = yes | 0 = no') +
  theme_minimal() +
  theme(
    legend.position = 'bottom'
  )

```


```{r Bill v default, echo=TRUE}

creditDf %>%
  select( bill_amt6, bill_amt5, bill_amt4, bill_amt3, bill_amt2, bill_amt1, default.payment.next.month) %>%
  gather(-default.payment.next.month, key = 'iv', value = 'value') %>%
  ggplot(aes(x = value,  fill = default.payment.next.month)) +
  geom_density() +
  facet_wrap(~iv) +
  xlim(0, 75000) +
  ylab('Density') +
  xlab('Amount of Bill Statement ($)') +
  labs(fill = 'Default 1 = yes | 0 = no') +
  theme_minimal() +
  theme(
    legend.position = 'bottom',
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) 


```

```{r Pay v default, echo=TRUE}

creditDf %>%
  select( pay_amt6, pay_amt5, pay_amt4, pay_amt3, pay_amt2, pay_amt1, default.payment.next.month) %>%
  gather(-default.payment.next.month, key = 'iv', value = 'value') %>%
  ggplot(aes(x = value,  fill = default.payment.next.month)) +
  geom_density() +
  facet_wrap(~iv) +
  xlim(0, 10000) +
  ylab('Density') +
  xlab('Amount of Previous Payment ($)') +
  labs(fill = 'Default 1 = yes | 0 = no') +
  theme_minimal() +
  theme(
    legend.position = 'bottom',
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) 

```


This is a histogram of each of the variables. 

```{r IV box plots, echo=TRUE}

creditDf %>% 
  sample_n(50) %>% #samples from the data set to improve speed
  gather(-default.payment.next.month, key = 'iv', value = 'value') %>%
  ggplot(aes(y = value,  group = default.payment.next.month, x = default.payment.next.month)) +
  geom_boxplot() +
  facet_wrap(~iv, scales = 'free') +
  ggtitle('Histograms of the Variables') +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  ) 
  

```
The next code block creates histograms and density plots for the categorical and continuous variables, respectively. 

```{r histograms, echo=TRUE}

#histograms of categorical data
categorical %>%
  sample_n(30) %>%
  gather(key = 'var', value = 'value') %>%
  ggplot(aes(x = value)) +
  geom_histogram(stat = 'count') +
  facet_wrap(~var, scales = 'free') +
  xlab('Variable') +
  ylab('Count') +
  ggtitle('Histograms of All Categorical Variables') +
  theme_minimal() +
  theme(
    #axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.title.x = element_blank()
  )

#histograms of continuous data
continuous %>%
  sample_n(30) %>%
  gather(key = 'var', value = 'value') %>%
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~var, scales = 'free') +
  ylab('Density') +
  ggtitle('Density Plots of All Continuous Variables') +
  theme_minimal() +
  theme(
    #axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(), 
    axis.title.x = element_blank(),
    
  )
  
  

```

The below code chunk visualizes two variables and the groups the data by whether or not they defaulted. 

```{r Scatter plots, echo=TRUE}

#Average Bill Amount vs. Average Pay Amount
creditDf %>%
  ggplot(aes(x = bill_avg, y = pay_avg, color = default.payment.next.month)) +
  geom_point() +
  theme_minimal() +
  theme(
    legend.position = 'bottom'
  )

#Age vs. Average Bill Amount
creditDf %>%
  ggplot(aes(x = age, y = pay_avg, color = default.payment.next.month)) +
  geom_point() +
    theme_minimal() +
  theme(
    legend.position = 'bottom'
  )

creditDf %>%
  ggplot(aes(x = age, y = bill_avg, color = default.payment.next.month)) +
  geom_point() +
    theme_minimal() +
  theme(
    legend.position = 'bottom'
  )

creditDf %>%
  ggplot(aes(x = avg_credit_usage, fill = default.payment.next.month)) +
  geom_bar() +
    theme_minimal() +
  theme(
    legend.position = 'bottom'
  )


```

The below chunk of code visualizes the demographic variables and their relation to defaulting. 

```{r Default v Demo, echo=TRUE}

#Limit Balance
creditDf_LB <- creditDf %>% group_by(limit_bal, default.payment.next.month) %>% summarise(Counts = n())
head(creditDf_LB)
names(creditDf_LB) <- c("LIMIT_BAL","default","Counts") 
lbdist = ggplot(creditDf_LB, aes(x=factor(LIMIT_BAL), y=Counts, fill=factor(default))) + 
      geom_bar(stat="identity") + 
      xlab('Limit Balanace')+
      ylab('Total')+
      theme_minimal()+
      ggtitle("Limit Balance Distribution") +
      theme(
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = 'bottom'
      )
lbdist = lbdist + guides(fill=guide_legend(title ='Default Payment: 0 = No Default | 1 = Default' )) ; lbdist
##The customers who have lower limit balance have much more higher default rate.

#Gender
creditDf_Sex <- creditDf %>% group_by(sex, default.payment.next.month) %>% summarise(Count = n())
head(creditDf_Sex)
names(creditDf_Sex) <- c("SEX","default","Count") 
genderdist = ggplot(creditDf_Sex, aes(x=factor(SEX), y=Count, fill=factor(default))) + 
      geom_bar(stat="identity") + 
      xlab('Gender: 0 = Male | 1 = Female')+
      ylab('Total')+
      theme_minimal()+
      ggtitle("Gender Distribution") +
      theme(
        legend.position = 'bottom'
      )
genderdist = genderdist + guides(fill=guide_legend(title ='Default Payment: 0 = No Default | 1 = Default' )) ; genderdist
##The customers who are defined as 'Female' have a lower default rate.

#Education
creditDf_Edu <- creditDf %>% group_by(education, default.payment.next.month) %>% summarise(Count = n())
head(creditDf_Edu)
names(creditDf_Edu) <- c("EDU","default","Count") 
edudist = ggplot(creditDf_Edu, aes(x=factor(EDU), y=Count, fill=factor(default))) + 
      geom_bar(stat="identity") + 
      xlab('Education: 1 = Grad School, 2 = Under Grad, 3 = High School, 4 = Others')+
      ylab('Total')+
      theme_minimal()+
      ggtitle("Educatiton Distribution")
edudist = edudist + guides(fill=guide_legend(title ='Default Payment: 0 = No Default | 1 = Default' )) ; edudist
##The Customers who have competed undergrad have a higher default rate.

#Marriage
creditDf_Mar <- creditDf %>% group_by(marriage, default.payment.next.month) %>% summarise(Count = n())
names(creditDf_Mar) <- c("MAR","default","Count")
creditDf_Mar = creditDf_Mar %>% filter(MAR != 0)
mardist = ggplot(creditDf_Mar, aes(x=factor(MAR), y=Count, fill=factor(default))) + 
      geom_bar(stat="identity") + 
      xlab('Martial Status: 1 = Married, 2 = Single, 3 = Others')+
      ylab('Total')+
      theme_minimal()+
      ggtitle("Marriage Distribution") +
      theme(
        legend.position = 'bottom'
      )
mardist = mardist + guides(fill=guide_legend(title ='Default Payment: 0 = No Default | 1 = Default' )) ; mardist
##Married and Single Customers have a apprx the same default rate.

#Age
creditDf_Age <- creditDf %>% group_by(age, default.payment.next.month) %>% summarise(Count = n())
head(creditDf_Age)
names(creditDf_Age) <- c("age","default","Count") 
agedist = ggplot(creditDf_Age, aes(x=age, y=Count, fill=factor(default))) + 
      geom_bar(stat="identity") + 
      xlab('Age')+
      ylab('Total')+
      theme_minimal()+
      ggtitle("Age Distribution") +
      theme(
        legend.position = 'bottom'
      )
agedist = agedist + guides(fill=guide_legend(title ='Default Payment: 0 = No Default | 1 = Default' )) ; agedist
##Younger customers have a higher default rate.



```



```{r Correaltions, echo=TRUE, echo=TRUE}
#lares::corr_cross(creditDf, type = 1)
#lares::corr_cross(creditDf, type = 1, ignore = c('pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6', 'bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5','bill_amt6', 'pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5','pay_amt6'))
#pairs(ccDate_demoinfo)
##Off initial review of core data (i.e. not payment data) limit balance, avg credit usage, and payment avg seem to have the largest correlation to whether or not a customer will default
```

# Analyze

# Classification Models

## Logistic Regression

### Computing Stepwise Logistic Regression


The first block of code uses only the demographic information to determine what, if any, demographic variables are associated with default. 

```{r demographic, echo=TRUE}

#Create a logistic model using only demographic variables. 
logit_modelDemographics <- glm(default.payment.next.month ~ sex + education + age + marriage
                              ,data = train, family = 'binomial')

summary(logit_modelDemographics)

```
The next block evaluates only the variables associated with payments. 

```{r payment, echo=TRUE}

logit_modelPayment <- glm(default.payment.next.month ~ bill_amt1 +  bill_amt2 + bill_amt3 + bill_amt4 + bill_amt5 + bill_amt6
                          + pay_amt1 + pay_amt2 + pay_amt3 + pay_amt4 + pay_amt5 + pay_amt6
                          + limit_bal + bill_avg + pay_avg + avg_credit_usage
                          + pay_0 + pay_2 + pay_3 + pay_4 + pay_5 + pay_6
                          ,data = train, family = 'binomial')

#Only Bill_Amt1 has a significant p-value
summary(logit_modelPayment)

```

The stepAIC() function is used to combine demographic and payment variables. 

```{r Stepwise Logistic}

# This will create an output that indicates the most significant predictors using the non-scaled data. 
logit_model1 <- glm(default.payment.next.month ~ . , data = train, family = 'binomial') %>%
  stepAIC(trace = FALSE)

summary(logit_model1)

# This produces the same output with scaled data. 
logit_model2 <- glm(default.payment.next.month ~ . , data = train_scaled, family = 'binomial') %>%
  stepAIC(trace = FALSE)

summary(logit_model2)

# Both of these code chunks take a few minutes to complete running. 

```

The StepAIC() functions helps to determine which variables to retain in the final model. The following code chunk uses different combinations of the recommended variables in an effort to develop a model with a lower AIC score. 

```{r logit model1, echo=TRUE}

logit_model1B <- glm(default.payment.next.month ~ limit_bal + sex + education + marriage 
                     + pay_0 + bill_amt1 + bill_amt4 + bill_amt6
                     + pay_amt1 + pay_amt2 + pay_amt3 + pay_amt4 + pay_amt5 + pay_amt6
                     + bill_avg + avg_credit_usage, data = train, family = 'binomial')

summary(logit_model1B)

logit_model2B <- glm(default.payment.next.month ~ scaled.limit_bal + sex + education + marriage 
                     + pay_0 + scaled.bill_amt1 + scaled.bill_amt4 + scaled.bill_amt6
                     + scaled.pay_amt1 + scaled.pay_amt2 + scaled.pay_amt3 + scaled.pay_amt4 + scaled.pay_amt5 
                     + scaled.bill_avg + scaled.avg_credit_usage, data = train_scaled, family = 'binomial')

summary(logit_model2B)

logit_model2C <- glm(default.payment.next.month ~ scaled.limit_bal + sex + education + marriage 
                     + pay_0 + scaled.bill_amt1 
                     + scaled.pay_amt1 + scaled.pay_amt2 + scaled.pay_amt3 + scaled.pay_amt4 + scaled.pay_amt5 
                     + scaled.bill_avg + scaled.avg_credit_usage, data = train_scaled, family = 'binomial')

summary(logit_model2C)

logit_model2D <- glm(default.payment.next.month ~ scaled.limit_bal + sex 
                     + pay_0 + scaled.bill_amt1 
                     + scaled.pay_amt1 + scaled.pay_amt2 + scaled.pay_amt3 + scaled.pay_amt4 + scaled.pay_amt5 
                     + scaled.bill_avg + scaled.avg_credit_usage, data = train_scaled, family = 'binomial')

summary(logit_model2D)

logit_model2E <- glm(default.payment.next.month ~ scaled.limit_bal + sex * scaled.age
                     + pay_0 + scaled.bill_amt1 + scaled.bill_avg + 
                     + scaled.pay_amt1 + scaled.pay_amt2 + scaled.pay_amt3 + scaled.pay_amt4 + scaled.pay_amt5 
                     + scaled.avg_credit_usage, data = train_scaled, family = 'binomial')

summary(logit_model2E)

```

The key metric from each logistic model are compared. 

```{r compare logit, echo=TRUE}

#create a graph comparing logit models by AIC

logit.comparison <- data.frame(
  
  'Model' = c('Logistic Model 1', 'Logistic Model 1B', 'Logistic Model 2', 'Logistic Model 2B', 'Logistic Model 2C', 'Logistic Model 2D',
              'Logistic Model 2E', 'Logistic Model Demographics', 'Logistic Model Payments'),
  
  'AIC' = c(logit_model1$aic, logit_model1B$aic, logit_model2$aic, logit_model2B$aic, logit_model2C$aic, logit_model2D$aic, logit_model2E$aic,
            logit_modelDemographics$aic, logit_modelPayment$aic),
  
  'Rank' = c(logit_model1$rank, logit_model1B$rank, logit_model2$rank, logit_model2B$rank, logit_model2C$rank, logit_model2D$rank,
             logit_model2E$rank,logit_modelDemographics$rank, logit_modelPayment$rank),
  
  'Deviance' = c(logit_model1$deviance, logit_model1B$deviance, logit_model2$deviance, logit_model2B$deviance, logit_model2C$deviance,
                 logit_model2D$deviance,logit_model2E$deviance,logit_modelDemographics$deviance, logit_modelPayment$deviance),
  
  'Null Deviance' = c(logit_model1$null.deviance, logit_model1B$null.deviance, logit_model2$null.deviance, logit_model2B$null.deviance,
                      logit_model2C$null.deviance,logit_model2D$null.deviance,logit_model2E$null.deviance,logit_modelDemographics$null.deviance,
                      logit_modelPayment$null.deviance)
  
  
)

# Displays the table of metrics for the Logistic Model.
logit.comparison

# Sort the Models by AIC score. 
logit.comparison %>%
  select(Model, AIC) %>%
  arrange(AIC)

# Graphs the AIC score and model. 
logit.comparison %>%
  ggplot(aes(x = Model, y = AIC)) +
  geom_col() +
  ggtitle('AIC for Each Logistic Model') +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


```


### Making Predictions with the Logistic Models

```{r logit prediction, echo=TRUE}

# Logistic Model 2
# Logistic Model Payments
# Logistic Model Demographics



test.results <- test %>%
  mutate(
    
    'logistic.model2.probability' = predict(logit_model2, test_scaled, type = 'response'),
    'logistic.modelpayments.probability' = predict(logit_modelPayment, test, type = 'response'),
    'logistic.modeldemographics.probability' = predict(logit_modelDemographics, test, type = 'response')
    
  )

# This plots the ROC curve for Model 2
plot(
  performance(
  prediction(test.results$logistic.model2.probability, test.results$default.payment.next.month),
  'tpr',
  'fpr'
  ), colorsize = TRUE
  )
# This adds the line for the payments model. 
plot(
  performance(
  prediction(test.results$logistic.modelpayments.probability, test.results$default.payment.next.month),
  'tpr',
  'fpr'
  ), colorsize = TRUE, add = TRUE
  )
# This adds a line for the demographics model.The demographics model is as good as guessing. 
plot(
  performance(
  prediction(test.results$logistic.modeldemographics.probability, test.results$default.payment.next.month),
  'tpr',
  'fpr'
  ), colorsize = TRUE, add = TRUE
  )

# This line will determine the best cut-off values. 
coords(roc(default.payment.next.month ~ logistic.modeldemographics.probability, data = test.results), 'best')
coords(roc(default.payment.next.month ~ logistic.modelpayments.probability, data = test.results), 'best')
coords(roc(default.payment.next.month ~ logistic.modeldemographics.probability, data = test.results), 'best')

# Create predictions using the threshold value.
test.results <- test.results %>%
  mutate(
    logistic.model2.prediction = factor(ifelse(logistic.model2.probability > 
                                          coords(roc(default.payment.next.month ~ logistic.modeldemographics.probability, data = test.results), 'best')[, 1], 1, 0
                                        )),
    
    logistic.modelpayments.prediction = factor(ifelse(logistic.modelpayments.probability >
                                                 coords(roc(default.payment.next.month ~ logistic.modelpayments.probability, data = test.results), 'best')[, 1], 1, 0
                                              )),
    
    logistic.modeldemographics.prediction = factor(ifelse(logistic.modeldemographics.probability > 
                                                     coords(roc(default.payment.next.month ~ logistic.modeldemographics.probability, data = test.results), 'best')[, 1], 1, 0
                                                   ))
  )  

# This will create confusion matrices for each logistic model. 
confusionMatrix(test.results$logistic.model2.prediction, test.results$default.payment.next.month)
confusionMatrix(test.results$logistic.modelpayments.prediction, test.results$default.payment.next.month)
confusionMatrix(test.results$logistic.modeldemographics.prediction, test.results$default.payment.next.month)

# These lines of code will extract accuracy. 
confusionMatrix(test.results$logistic.model2.prediction, test.results$default.payment.next.month)$overall['Accuracy']
confusionMatrix(test.results$logistic.modelpayments.prediction, test.results$default.payment.next.month)$overall['Accuracy']
confusionMatrix(test.results$logistic.modeldemographics.prediction, test.results$default.payment.next.month)$overall['Accuracy']

```

The demographic variables of sex, education, and marriage are significant predictors of default. However, the model that solely relies on demographic variables to make predicts has a low accuracy. Demographic variables are not helpful in determining who might default. While it is illegal to use demographics when deciding whether or not too issue a card, there is no financial incentive in doing so. 

Bill Amt 1, each of the Pay Amt variables, and Pay_0 are all statistically significant predictors of default. The model that relies solely on payment variables has a decent accuracy. 


## k-Nearest Neighbors

k-Nearest Neighbors determines the classification of an observation based on the k closest neighbors. Closeness is defined using Euclidean distance. Each data point resides in space and the distance between each point is measured using the distance formula. In the example, we are using k equals 5. When a new point is presented, the class of the five closest neighbors is examined. Their class is used to determine the new points class.  

https://towardsdatascience.com/k-nearest-neighbors-algorithm-with-examples-in-r-simply-explained-knn-1f2c88da405c


```{r knn, echo=TRUE}

# The KNN neighbors model is trained on the scaled data set. 
prediction <- knn(train = train_scaled, test = test_scaled, cl = train_scaled$default.payment.next.month, k = 5)

# A confusion matrix is created with predictions. There is no need to create ROC curves, because the outcome of the KNN model is binary, not a probability. 
confusion_matrix <- table(prediction, test_scaled$default.payment.next.month)

confusion_matrix

# A function for calculating accuracy is created. 
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x))))}

# The accurancy is stored in a variable for later use. 
accuracy.knn <- accuracy(confusion_matrix)

accuracy.knn 

```

This accuracy is insanely high, there must be target leakage. 


## Random Forest 

https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/

### Train the Random Forest Model

```{r train rf, echo=TRUE}

# Model 1
rf_classifer = randomForest(default.payment.next.month ~ ., data = train, ntree = 100, mtry = 2, importance = TRUE)

rf_classifer

varImpPlot(rf_classifer)

# Model 2
rf_classifer_2 = randomForest(default.payment.next.month ~ pay_0 + pay_2 + pay_3 + pay_4 + pay_4 +
                                bill_amt6 + bill_amt5 + bill_amt4 + bill_amt3 + bill_amt2 + bill_amt1 + avg_credit_usage +
                                pay_amt6 + pay_amt5 + pay_amt4 + pay_amt3 + pay_amt2 + pay_amt1 +
                                limit_bal
                                , data = train, ntree = 100, mtry = 2, importance = TRUE)

rf_classifer_2

varImpPlot(rf_classifer_2)

#There is hardly any reduction in the OOB estimate in model 2. From 18.62% to 18.52%.

```

### Predict with the Random Forest Classifer

```{r predict rf, echo=TRUE}

rf_prediction <- predict(rf_classifer_2, test)

table(observed = test$default.payment.next.month, predicted = rf_prediction)

rf_prediction_prob <-  predict(rf_classifer_2, test, type = 'prob')

true_value <- ifelse(test$default.payment.next.month == rf_prediction, 1, 0)

pred <- prediction(rf_prediction_prob[, 1], true_value)

perf <- performance(pred, 'tpr', 'fpr')

plot(perf)

auc.perf <- performance(pred, measure = 'auc')

accuracy.rf <- as.numeric(auc.perf@y.values)

print(auc.perf@y.values)



```


## GBM Model

Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in an iterative fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiate loss function. 

https://koalaverse.github.io/machine-learning-in-R/gradient-boosting-machines.html

```{r GBM Prediction, echo=TRUE, message=FALSE, warning=FALSE}

# Train model with preprocessing & repeated cv
model_gbm <- caret::train(default.payment.next.month ~ .,
                          data = train,
                          method = "gbm",
                          preProcess = c("scale", "center"),
                          trControl = trainControl(method = "repeatedcv", 
                                                  number = 5, 
                                                  repeats = 3, 
                                                  verboseIter = FALSE),
                          verbose = 0, na.action=na.exclude)
model_gbm

# Test GBM Model against Test Data
pred.int <- predict(model_gbm, test, interval = "prediction")#; pred.int
gbm_data_frame <- cbind(test$default.payment.next.month, pred.int)#; gbm_data_frame
gbm_data_frame = as.data.frame(gbm_data_frame)#; gbm_data_frame


gbm.correct <- rep(0, nrow(gbm_data_frame))
for (i in 1:nrow(gbm_data_frame)) {
  gbm.correct[i] <- ifelse(gbm_data_frame$V1[i] == gbm_data_frame$pred.int[i], 1, 0)
}

accuracy.gbm <- sum(gbm.correct)/length(gbm.correct)

```

## Model Comparison (Accuracy)

```{r accuracy comparison, echo=TRUE}

model.comparison <- data.frame(
  
  Model = c('Logistic Model 2', 
            'Logistic Model Payments', 
            'Logistic Model Demographics', 
            'KNN Model', 
            'Random Forest', 
            'GMB Model'
            ),
  Accuracy = c(confusionMatrix(test.results$logistic.model2.prediction, test.results$default.payment.next.month)$overall['Accuracy'], 
               confusionMatrix(test.results$logistic.modelpayments.prediction, test.results$default.payment.next.month)$overall['Accuracy'],
               confusionMatrix(test.results$logistic.modeldemographics.prediction, test.results$default.payment.next.month)$overall['Accuracy'],
               round(accuracy.knn, 3), 
               round(accuracy.rf,3), 
               round(accuracy.gbm, 3)
               )
  
)


model.comparison

model.comparison %>%
  arrange(Accuracy) %>%
  ggplot(aes(x = Model, y = Accuracy)) +
  geom_col() +
  ggtitle('Accuracy of the Models') +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```


## Conclusion
